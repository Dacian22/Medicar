{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) NetworkxEntityGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/use_cases/graph/integrations/graph_networkx_qa#create-the-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from langchain.indexes import GraphIndexCreator\n",
    "from langchain.indexes.graph import NetworkxEntityGraph\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import GraphQAChain\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read csv file and skip first row\n",
    "# highway_type = pd.read_csv('edge_labels_highways.csv', header=None, skiprows=1,\n",
    "#                  names=['edge', 'highway type'])\n",
    "# # split the first column into two columns\n",
    "# highway_type['edge'] = highway_type['edge'].apply(lambda x: eval(x))\n",
    "\n",
    "# # Split the 'edge' column into two columns 'start' and 'end'\n",
    "# highway_type[['startNode', 'endNode']] = highway_type['edge'].apply(pd.Series)\n",
    "# # convert the values into strings\n",
    "# highway_type['startNode'] = highway_type['startNode'].astype(str)\n",
    "# highway_type['endNode'] = highway_type['endNode'].astype(str)\n",
    "# # Drop the 'edge' column\n",
    "# highway_type.drop('edge', axis=1, inplace=True)\n",
    "\n",
    "# # create networkx graph based on csv files\n",
    "# G = nx.read_edgelist(\"..\\\\csv\\\\edges_UH_Graph.csv\", delimiter=\",\", create_using=nx.DiGraph(), nodetype=str)\n",
    "# # add labels to edges according to highway\n",
    "# for u,v in G.edges():\n",
    "#     if (u,v) in zip(highway_type['startNode'], highway_type['endNode']):\n",
    "#         G[u][v]['relation'] = 'highway type: ' + str(highway_type['highway type'].loc[(highway_type['startNode'] == u) & (highway_type['endNode'] == v)].values[0])\n",
    "#     else:\n",
    "#         G[u][v]['relation'] = 'highway type: unknown'\n",
    "\n",
    "# # write the graph to a GML file\n",
    "# nx.write_gml(G, \"UH_Graph.gml\")\n",
    "\n",
    "# # read the graph from the GML file\n",
    "# G = nx.read_gml(\"UH_Graph.gml\")\n",
    "\n",
    "# # load gml graph as NetworkxEntityGraph\n",
    "# G = nx.read_gml(\"UH_Graph.gml\")\n",
    "# G_NX = NetworkxEntityGraph(G)\n",
    "\n",
    "# # print amount of nodes\n",
    "# print(\"Nodes:\", G_NX.get_number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the chain\n",
    "# chain = GraphQAChain.from_llm(OpenAI(), graph = G_NX, verbose = True)\n",
    "\n",
    "# # prompt\n",
    "# node_1 = '31404364'\n",
    "# node_2 = '313157654'\n",
    "\n",
    "# prompt = 'Which is the highway type between node {node_1} and node {node_2} from the graph you received as input?'\n",
    "\n",
    "# # chain.run(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: This is created for Knowledge Graphs, not for our graph!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Special nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read special nodes from csv file\n",
    "with open('..\\\\csv\\\\special_nodes_UH_Graph.csv') as f:\n",
    "    special_nodes = str(f.readlines())\n",
    "# special_nodes = pd.read_csv('..\\\\csv\\\\special_nodes_UH_Graph.csv')\n",
    "\n",
    "# read case examples from csv file with index\n",
    "examples = pd.read_csv('..\\\\..\\\\Playground_LLM\\\\examples.csv', sep=';')\n",
    "examples = examples.drop(columns=['Unnamed: 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     There is a fire alarm going off at Zentralküche.\n",
       "1    There is a power outage at Klinik für Radiolog...\n",
       "2    There is a radiation leak at Klinik für Strahl...\n",
       "Name: examples, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples['examples'].iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''\n",
    "    You are a helpful assistant. You are asked to provide information about the impact on traffic of a given action on a network of nodes.\n",
    "    Think about some possible impacts of the action like people crowds, traffic jams, blocked roads, etc., that influence the traffic flow.\n",
    "    Please respond to given example only based on the given context that includes the name of the nodes and its coordinates.\n",
    "    You have to really think about the geographic position and the local environment of the impact position and how the action affects nodes in the environment.\n",
    "    All nodes in the context determine the complete map. Keep that in mind when evaluating the distance between nodes based on their geographic position.\n",
    "    IMPORTANT: Do not only consider the names of the nodes!\n",
    "    The final answer should only include the list of directly affected nodes which have to have the names of the nodes in the context and for every node an explanation.\n",
    "     '''),\n",
    "    (\"user\", \"Action: {example}\\nContext: {context}\"),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "example = examples['examples'].iloc[7]\n",
    "context = special_nodes\n",
    "\n",
    "# loop over first three examples\n",
    "for example in examples['examples'].iloc[:3]:\n",
    "    chain.invoke({\"example\": example, \"context\": context})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
