{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import BuildGraph\n",
    "import warnings\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "parameters = {\n",
    "    \"subgraph_params\": {\n",
    "        'special_nodes': ['Emmaus Kapelle', 'Apotheke des Universitätsklinikums',\n",
    "                 'Neurozentrum', 'Café am Ring', 'Die Andere Galerie', 'Augenklinik / HNO',\n",
    "                 'Tonus', 'Neurozentrum', 'Café am Eck', 'Bistro am Lorenzring',\n",
    "                 'Urologie', 'Luther Kindergarten', 'Kiosk Frauenklinik', 'Ernährungsmedizin',\n",
    "                 'Medienzentrum', '3SAM Tagespflege', 'Klinik für Onkologische Rehabilitation',\n",
    "                 'Stimme vom Berg', 'Klinik für Frauenheilkunde', 'Cafeteria im Casino',\n",
    "                 'Sympathy', 'Die Himmelsleiter', 'Zwischen den Räumen',\n",
    "                 'Terrakotta', 'Große Kugelkopfsäule', 'Freischwimmer', 'Notaufnahme', 'Gum',\n",
    "                 'Tripylon', 'Notfallpraxis der niedergelassenen Ärzte', 'Klinik für Palliativmedizin',\n",
    "                 'Lebensalter', 'Blutspende Freiburg', 'Christian Daniel Nussbaum','Das große Spiel',\n",
    "                 'Hippokrates von Kos', 'Theodor Billroth',\n",
    "                 'Adolf Lorenz', 'Universitätsklinikum Freiburg - Klinik für Innere Medizin'],\n",
    "        'allowed_highway_types': ['footway', 'unclassified', 'service', 'platform',\n",
    "                                  'steps', 'residential', 'construction', 'path', 'secondary_link',\n",
    "                                  'tertiary', 'pedestrian', 'secondary', 'cycleway'],\n",
    "        'allowed_surface_types': [None, 'grass_paver', 'paving_stones', 'asphalt', 'cobblestone', 'sett']},\n",
    "}\n",
    "\n",
    "\n",
    "G, edge_df, nodes_df = BuildGraph.build_nx_graph(\n",
    "        parameters['subgraph_params']['allowed_highway_types'],\n",
    "        parameters['subgraph_params']['allowed_surface_types'],\n",
    "        parameters['subgraph_params']['special_nodes'])\n",
    "\n",
    "method=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_edges(given_node):\n",
    "    \"\"\"Return the edges connected to the specified node in the graph.\"\"\"\n",
    "    \n",
    "    if given_node in G:\n",
    "        connected_edges = list(G.edges(given_node))\n",
    "        connected_edges = {\n",
    "            \"connected_edges\": list(G.edges(given_node)),\n",
    "        }              \n",
    "    else:\n",
    "        connected_edges = {\n",
    "            \"connected_edges\": \"\",\n",
    "        }\n",
    "\n",
    "    return json.dumps(connected_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "    {\n",
    "        \"name\": \"get_connected_edges\",\n",
    "        \"descripton\": \"Get the connected edges to a specific node in a graph.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"given_node\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A specific node in a graph. \",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_usability =  f\"\"\"You are a graph expert and you are given the graph of a university hospital\n",
    "                campus. Nodes are the buildings in the graph and edges are the routes between\n",
    "                the buildings.  You will be given some information that something is happening \n",
    "                at a specific node or edge. You need to determine if what is happening will have an\n",
    "                impact in transporting goods through edges. \n",
    "                Only take into consideration transportation outside the buildings and not within buildings. \n",
    "                You can rely on the given examples to determine the importance of an event. \n",
    "                Examples: \n",
    "                Question: Someone fell at edge edge_N3_N4. Does this impact the transportation? \\n\n",
    "                Answer: True, the event will have an impact in transportation and the edge is not usable.\\n\n",
    "                Question: Someone dropped their ice cream at edge_N1_N2. Does this impact the transportation? \\n \n",
    "                Answer:   False, the event won't have an impact in transportation and the edge is usable. \\n\n",
    "                Question: There is a fire alarm going off at node 2. Does it impact the transportation? \\n\n",
    "                Answer:  True, the event will have an impact in transportation and other nodes are impacted as well. \\n\n",
    "                Question: There is a surgery going on at node C. Does it impact the transportation? \\n \n",
    "                Anwer: False, the event won't have an impact in transportation and only the current node is impacted by this event. \\n\"\"\"\n",
    "user_prompt = input(\"Please enter your prompt: \")\n",
    "full_prompt_usability = f\"{context_usability} \\n {user_prompt}\"\n",
    "\n",
    "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "response_usability = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages = [{'role': 'user', 'content': full_prompt_usability}],\n",
    "    max_tokens=300,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "output_usability = response_usability.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_content = output_usability.content.strip().lower()\n",
    "\n",
    "if \"true\" in response_content and \"edge\" in response_content:\n",
    "    context_dynamic =  f\"\"\"As a professional graph modeler, you're tasked with determining the \n",
    "    accessibility of edges in a transportation network. You are given an event that impacts\n",
    "    the usability of the edge. Now, you must determine whether this event wuld impact the whole\n",
    "    length of the edge or it happens in a single point of the edge. \n",
    "    You can rely on the given examples to determine the importance of an event. \n",
    "\n",
    "    Examples: \n",
    "    Question: Someone fell at edge edge_N3_N4. Does this impact the whole length of the edge? \\n\n",
    "    Answer:   False, the event will impact only part of the edge edge_N3_N4.\\n\n",
    "    Question: At edge edge_A_B a barrier blocks the entrance. Does this impact the whole length of the edge? \\n \n",
    "    Answer:   True, the event will impact the whole edge edge_A_B. \\n\n",
    "    Question: At edge edge_A_B the pathway is covered in thick mud due to recent rain. Does this impact the whole length of the edge? \\n\n",
    "    Answer:   True, the event will impact the whole edge edge_A_B. \\n\n",
    "    Question: At edge edge_A_B a bicycle is in the midle of the edge.Does this impact the whole length of the edge? \\n \n",
    "    Anwer:    False, the event will impact only part of the edge edge_A_B. \\n\"\"\"\n",
    "\n",
    "    full_prompt_dynamic = f\"{context_dynamic} \\n {user_prompt}\"\n",
    "\n",
    "    response_dynamic = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages = [{'role': 'user', 'content': full_prompt_dynamic}],\n",
    "    max_tokens=300,\n",
    "    temperature=0,\n",
    "    )\n",
    "\n",
    "    output_dynamic = response_dynamic.choices[0].message\n",
    "    response_content = output_dynamic.content.strip().lower()\n",
    "\n",
    "    if \"true\" in response_content:\n",
    "       context_length = f\"\"\"As a professional graph modeler, you're tasked with determining the \n",
    "       accessibility of edges in a transportation network. You must determine how much was the \n",
    "       provided edge affected based on how important the event given as input is. \n",
    "       The values are between 0-100 with 100 being the most affected, values between 0-25 are for \n",
    "       events that affect the accessibility of the edge a little bit, values between 25-50 are for \n",
    "       events that moderately affect the accessibility of the edge, values between 50-75 are for \n",
    "       events that seriously affect the accessibility of the edge and values between 75-100\n",
    "       affect the accessibility of the edge critically. \n",
    "       You can rely on the given examples to determine the importance of an event. \n",
    "\n",
    "        Examples: \n",
    "        Question: At edge edge_A_B a barrier blocks the entrance. Please provide a mandatory single value between 0 and 100 for how much is the accessibility of the edge affected. \\n \n",
    "        Answer:   The value is 98. \\n\n",
    "        Question: At edge edge_A_B the pathway is covered in thick mud due to recent rain. Please provide a mandatory single value between 0 and 100 for how much is the accessibility of the edge affected. \\n\n",
    "        Answer:   The value is 70. \\n\n",
    "\n",
    "        Please provide a mandatory single value between 0 and 100 for how much the accessibility of \n",
    "        the edge for the transportation vehicles is affected. Format it exactly like this: The value is X.\"\"\"\n",
    "       \n",
    "       full_prompt_length = f\"{context_length} \\n {user_prompt}\"\n",
    "\n",
    "       response_length = client.chat.completions.create(\n",
    "       model=\"gpt-3.5-turbo\",\n",
    "       messages = [{'role': 'user', 'content': full_prompt_length}],\n",
    "       max_tokens=300,\n",
    "       temperature=0,\n",
    "       )\n",
    "       \n",
    "       method = \"factor\"\n",
    "       output_length = response_length.choices[0].message\n",
    "\n",
    "    else:\n",
    "        context_time = f\"\"\"As a professional graph modeler, you're tasked with determining the \n",
    "        accessibility of edges in a transportation network. You are given an event that impacts the\n",
    "        accessability of an edge. Now, you must determine based on the event given what time penalty \n",
    "        should be applied to a vehicle if it passes through it.\n",
    "        You can rely on the given examples to determine the importance of an event.\n",
    "\n",
    "        Examples: \n",
    "        Question: Someone fell at edge edge_N3_N4. Please provide a mandatory single value in minutes for how much time will the vehicle be delayed. \\n\n",
    "        Answer:   The value is 15 minutes.\\n\n",
    "        Question: At edge edge_A_B a bicycle is in the midle of the edge.Please provide a mandatory single value in minutes for how much time will the vehicle be delayed. \\n \n",
    "        Anwer:    The value is 30 minutes. \\n\n",
    "\n",
    "        Please provide a mandatory single value in minutes for how much is the accessibility of the edge \n",
    "        for the transportation vehicles is affected. Format it exactly like this: The value is X minutes.\"\"\"\n",
    "       \n",
    "        full_prompt_time = f\"{context_time} \\n {user_prompt}\"\n",
    "\n",
    "        response_time = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = [{'role': 'user', 'content': full_prompt_time}],\n",
    "        max_tokens=300,\n",
    "        temperature=0,\n",
    "        )\n",
    "       \n",
    "        method = \"minutes\"\n",
    "        output_time = response_time.choices[0].message\n",
    "\n",
    "elif \"true\" in response_content and \"node\" in response_content:\n",
    "    context_nodes = f\"\"\"You are a graph expert and you are given the graph of a university hospital\n",
    "            campus. Nodes are the buildings in the graph and edges are the routes between\n",
    "            the buidlings. Autonomous vehicles are transporting goods throughout the edges.\n",
    "            You will be given some information that something is happening at a specific node. Now,\n",
    "            you need to determine which edges are impacted from this event. Be concise and only give the \n",
    "            list of impacted edges in this format for each edge 'edge_node1_node2'.\"\"\"\n",
    "    \n",
    "    full_prompt_nodes= f\"{context_nodes} \\n {user_prompt}\"\n",
    "\n",
    "    response_nodes = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = [{'role': 'user', 'content': full_prompt_nodes}],\n",
    "        max_tokens=300,\n",
    "        temperature=0,\n",
    "        functions=function_descriptions,\n",
    "        function_call=\"auto\",\n",
    "        )\n",
    "       \n",
    "        \n",
    "    output_nodes = response_nodes.choices[0].message\n",
    "\n",
    "    if output_nodes.function_call:\n",
    "        params = json.loads(output_nodes.function_call.arguments)\n",
    "        chosen_function = eval(output_nodes.function_call.name)\n",
    "        answer = chosen_function(**params)\n",
    "\n",
    "\n",
    "        response_nodes = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = [{'role': 'user', 'content': full_prompt_nodes},\n",
    "                        {'role': \"function\", \"name\": output_nodes.function_call.name, \"content\": answer},\n",
    "            ],\n",
    "            max_tokens=300,\n",
    "            functions=function_descriptions,\n",
    "        )\n",
    "\n",
    "        output_nodes = response_nodes.choices[0].message\n",
    "\n",
    "        context_nodes_time = f\"\"\"You're a graph expert and you are given a graph representing a hospital \n",
    "        campus where nodes are buildings and edges are the routes between buildings. Autonomous vehicles \n",
    "        transport goods along these edges. You will be given certain events happening in buildings that\n",
    "        cause people to go outside, leading to crowds on the surrounding edges and delaying transportation.\n",
    "        You need to determine the severity of the event and estimate a time delay for the vehicle based\n",
    "        on the severity.\n",
    "        You can rely on the given examples to determine the severity of an event.\n",
    "\n",
    "            Examples: \n",
    "            Question: The ceiling has collapsed on node 2. Please provide a mandatory single value in minutes for how much time will the vehicle be delayed. \\n\n",
    "            Answer:   The value is 120 minutes.\\n\n",
    "            Question: A smoke detection alarm is going off at node 1.Please provide a mandatory single value in minutes for how much time will the vehicle be delayed. \\n \n",
    "            Anwer:    The value is 30 minutes. \\n\n",
    "            Question: Routine maintenance is happening at node 3. Please provide a mandatory single value in minutes for how much time will the vehicle be delayed.\n",
    "            Answer: The value is 15 minutes.\n",
    "\n",
    "        Please provide a mandatory single value in minutes for how much the vehicle will be delayed. \n",
    "        Format it exactly like this: The value is X minutes.\n",
    "            \"\"\"\n",
    "    \n",
    "        full_prompt_nodes_time= f\"{context_nodes_time} \\n {user_prompt}\"\n",
    "\n",
    "        response_nodes_time = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = [{'role': 'user', 'content': full_prompt_nodes_time}],\n",
    "        max_tokens=300,\n",
    "        temperature=0.3,\n",
    "        )\n",
    "\n",
    "        output_nodes_time = response_nodes_time.choices[0].message\n",
    "       \n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
