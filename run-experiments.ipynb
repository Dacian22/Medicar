{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:53:41.299260Z",
     "start_time": "2024-10-08T12:53:41.296771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "sys.path.append('./_01_Simulation/')\n",
    "\n",
    "import _01_Simulation.LLM_Edge_Usability\n",
    "import _01_Simulation.LLM_Dynamic_Weights\n",
    "import _01_Simulation.LLM_MetaModel"
   ],
   "id": "3d419cfad8ae5e35",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:53:46.591761Z",
     "start_time": "2024-10-08T12:53:46.586626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load .env file\n",
    "dotenv.load_dotenv()"
   ],
   "id": "1f561e7e91c8d35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:10.924517Z",
     "start_time": "2024-10-08T12:46:10.922172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Deactivate deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ],
   "id": "fdc8719023c3029e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Edge usability",
   "id": "ad46b5e6f445a87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:10.926862Z",
     "start_time": "2024-10-08T12:46:10.925048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Params (currently only considers openai models\n",
    "approaches = [\"zeroshot\", \"fewshot\"]"
   ],
   "id": "df76334181794a14",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:10.932140Z",
     "start_time": "2024-10-08T12:46:10.928232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load evaluation csv\n",
    "df_evaluation = pd.read_csv(os.path.join(os.getenv('RESOURCES'), 'EvaluationDataset.csv'), sep=\";\")"
   ],
   "id": "42a0d76d145bb7da",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:10.937268Z",
     "start_time": "2024-10-08T12:46:10.932657Z"
    }
   },
   "cell_type": "code",
   "source": "df_evaluation.head()",
   "id": "ae7913f8d99a6a29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              action  edgeUsable\n",
       "0                       A person fell on the ground.       False\n",
       "1  There is an unexpected construction on the usu...       False\n",
       "2                 Fallen branches from nearby trees.       False\n",
       "3              Street cleaning crew sweeping debris.       False\n",
       "4        The sidewalk is obstructed by a parked car.       False"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>edgeUsable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person fell on the ground.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is an unexpected construction on the usu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fallen branches from nearby trees.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Street cleaning crew sweeping debris.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The sidewalk is obstructed by a parked car.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:10.940209Z",
     "start_time": "2024-10-08T12:46:10.938175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO Remove this statement to evaluate the whole dataset. This will induce extensive costs for API usage.\n",
    "df_evaluation = df_evaluation.iloc[:2]"
   ],
   "id": "ef7371ab95fab406",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:18.414751Z",
     "start_time": "2024-10-08T12:46:10.940739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Invoke GPT-3.5 to obtain the predictions for edge-usability\n",
    "\n",
    "for approach in approaches:\n",
    "    print(f\"Approach: {approach}\")\n",
    "    predictions = []\n",
    "    for index, row in df_evaluation.iterrows():\n",
    "        model_output = _01_Simulation.LLM_Edge_Usability.invoke_llm(row[\"action\"], model_type=\"openai\", approach=approach)\n",
    "        prediction = _01_Simulation.LLM_Edge_Usability.parse_response(model_output)\n",
    "        predictions.append(prediction)\n",
    "        print(f\"Finished {index+1}/{len(df_evaluation)}\")\n",
    "    \n",
    "    df_evaluation[\"prediction\"] = predictions\n",
    "    df_evaluation.to_csv(os.path.join(os.getenv('RESULTS'), f'eval-res-edge-usability-openai-{approach}-{datetime.datetime.now().isoformat()}.csv'), sep=\";\", index=False)"
   ],
   "id": "cbfa9e52b0bfa3c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach: zeroshot\n",
      "Finished 1/2\n",
      "Finished 2/2\n",
      "Approach: fewshot\n",
      "Finished 1/2\n",
      "Finished 2/2\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Dynamic Edge Weights",
   "id": "d594d55fc6a6d1bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:18.419572Z",
     "start_time": "2024-10-08T12:46:18.416587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Params (currently only considers openai models\n",
    "approaches = [\"zeroshot\", \"fewshot\"]"
   ],
   "id": "908861a429177869",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:18.425963Z",
     "start_time": "2024-10-08T12:46:18.421261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load evaluation csv\n",
    "df_evaluation = pd.read_csv(os.path.join(os.getenv('RESOURCES'), 'EvaluationDataset-dynamic-edge-weight.csv'), sep=\";\")"
   ],
   "id": "a69b7fc418cee727",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:18.435217Z",
     "start_time": "2024-10-08T12:46:18.427388Z"
    }
   },
   "cell_type": "code",
   "source": "df_evaluation.head()",
   "id": "e3094764c2e2a155",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              action  lengthDependency  \\\n",
       "0                       A person fell on the ground.             False   \n",
       "1  There is an unexpected construction on the usu...              True   \n",
       "2                 Fallen branches from nearby trees.             False   \n",
       "3              Street cleaning crew sweeping debris.             False   \n",
       "4        The sidewalk is obstructed by a parked car.             False   \n",
       "\n",
       "   LLMAnswer  \n",
       "0      False  \n",
       "1       True  \n",
       "2      False  \n",
       "3      False  \n",
       "4      False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>lengthDependency</th>\n",
       "      <th>LLMAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person fell on the ground.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is an unexpected construction on the usu...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fallen branches from nearby trees.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Street cleaning crew sweeping debris.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The sidewalk is obstructed by a parked car.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:18.439957Z",
     "start_time": "2024-10-08T12:46:18.437279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO Remove this statement to evaluate the whole dataset. This will induce extensive costs for API usage.\n",
    "df_evaluation = df_evaluation.iloc[:2]"
   ],
   "id": "ad5087da3ed3776",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:18.447487Z",
     "start_time": "2024-10-08T12:46:18.441622Z"
    }
   },
   "cell_type": "code",
   "source": "df_evaluation",
   "id": "53d5beb969070780",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              action  lengthDependency  \\\n",
       "0                       A person fell on the ground.             False   \n",
       "1  There is an unexpected construction on the usu...              True   \n",
       "\n",
       "   LLMAnswer  \n",
       "0      False  \n",
       "1       True  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>lengthDependency</th>\n",
       "      <th>LLMAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person fell on the ground.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is an unexpected construction on the usu...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:31.861947Z",
     "start_time": "2024-10-08T12:46:18.456343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Invoke GPT-3.5 to obtain the predictions for dynamic-edge-weights\n",
    "\n",
    "for approach in approaches:\n",
    "    print(f\"Approach: {approach}\")\n",
    "    predictions = []\n",
    "    result_types = []\n",
    "    for index, row in df_evaluation.iterrows():\n",
    "        model_output, _, result_type = _01_Simulation.LLM_Dynamic_Weights.invoke_llm_chain(row[\"action\"], model_type=\"openai\", approach=approach)\n",
    "        prediction = _01_Simulation.LLM_Dynamic_Weights.parse_output_weights(model_output)\n",
    "        predictions.append(prediction)\n",
    "        result_types.append(result_type)\n",
    "        print(f\"Finished {index+1}/{len(df_evaluation)}\")\n",
    "    \n",
    "    df_evaluation[\"prediction\"] = predictions\n",
    "    df_evaluation[\"result_type\"] = result_types\n",
    "    df_evaluation.to_csv(os.path.join(os.getenv('RESULTS'), f'eval-res-dynamic-openai-{approach}-{datetime.datetime.now().isoformat()}.csv'), sep=\";\", index=False)"
   ],
   "id": "e47ea24722a02d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach: zeroshot\n",
      "Finished 1/2\n",
      "Finished 2/2\n",
      "Approach: fewshot\n",
      "Finished 1/2\n",
      "Finished 2/2\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Functioncalling",
   "id": "2379f604a55a73e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "i",
   "id": "25327227da757989"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Meta-Model",
   "id": "929f4322f06811b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:31.869222Z",
     "start_time": "2024-10-08T12:46:31.863571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load evaluation csv\n",
    "df_evaluation = pd.read_csv(os.path.join(os.getenv('RESOURCES'), 'EvaluationDataset-metamodel.csv'), sep=\";\")"
   ],
   "id": "6cd4000c9ba96202",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:31.876151Z",
     "start_time": "2024-10-08T12:46:31.870356Z"
    }
   },
   "cell_type": "code",
   "source": "df_evaluation.head()",
   "id": "e13a07fae22e00e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            examples\n",
       "0  There is a fire alarm going off at node 31451751.\n",
       "1        There is a power outage at node 5327549890.\n",
       "2            There is a gas leak at node 2895270992.\n",
       "3  An infectious disease outbreak was identified ...\n",
       "4  There is a big medical conference being held a..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is a fire alarm going off at node 31451751.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is a power outage at node 5327549890.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There is a gas leak at node 2895270992.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An infectious disease outbreak was identified ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is a big medical conference being held a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:46:31.882230Z",
     "start_time": "2024-10-08T12:46:31.878258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO Remove this statement to evaluate the whole dataset. This will induce extensive costs for API usage.\n",
    "df_evaluation = df_evaluation.iloc[:2]"
   ],
   "id": "926879033cdbe6f4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:53:22.412539Z",
     "start_time": "2024-10-08T12:46:31.884013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_usabilities = []\n",
    "output_dynamics = []\n",
    "output_lengths = []\n",
    "output_times = []\n",
    "output_nodes = []\n",
    "output_nodes_times = []\n",
    "for index, row in df_evaluation.iterrows():\n",
    "    output_usability, output_dynamic, output_length, output_time, output_node, output_nodes_time, _ = _01_Simulation.LLM_MetaModel.invoke_llm(row[\"examples\"])\n",
    "    output_usabilities.append(output_usability)\n",
    "    output_dynamics.append(output_dynamic)\n",
    "    output_lengths.append(output_length)\n",
    "    output_times.append(output_time)\n",
    "    output_nodes.append(output_node)\n",
    "    output_nodes_times.append(output_nodes_time)\n",
    "    print(f\"Finished {index+1}/{len(df_evaluation)}\")\n",
    "\n",
    "df_evaluation[\"output_usability\"] = output_usabilities\n",
    "df_evaluation[\"output_dynamic\"] = output_dynamics\n",
    "df_evaluation[\"output_length\"] = output_lengths\n",
    "df_evaluation[\"output_time\"] = output_times\n",
    "df_evaluation[\"output_node\"] = output_nodes\n",
    "\n",
    "df_evaluation.to_csv(os.path.join(os.getenv('RESULTS'), f'eval-res-metamodel-{datetime.datetime.now().isoformat()}.csv'), sep=\";\", index=False)"
   ],
   "id": "4a85f6f4eb5c8a88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1/2\n",
      "Finished 2/2\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
